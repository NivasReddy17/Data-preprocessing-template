{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_preprocessing_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nP110MIEx5-x"
      },
      "outputs": [],
      "source": [
        "#Impoerting Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Dataset\n",
        "df=pd.read_csv('Data_set_name.csv')\n",
        "x=df.iloc[:,:-1].values\n",
        "y=df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "hw4QGxhLyEfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "lMlxEMGiDLj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking or Missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "-ZtbVOQt2A1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') #mean,median or mode\n",
        "imputer.fit(x[])\n",
        "x[] = imputer.transform(x[])"
      ],
      "metadata": {
        "id": "hXL3gB9l2HBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding text data\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [row_number])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "K8K3odYZ22IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "x[] = le.fit_transform(x[])"
      ],
      "metadata": {
        "id": "W6GlpGaa3Tma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "JT8_V_8iyX6O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling\n",
        "#Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train[] = sc.fit_transform(x_train[])\n",
        "x_test[] = sc.transform(x_test[]) \n",
        "#Normalization\n",
        "from sklearn.preprocessing import Normalizer\n",
        "n=Normalizer()\n",
        "x_train[] = n.fit_transform(x_train[])\n",
        "x_test[] = n.transform(x_test[])"
      ],
      "metadata": {
        "id": "oCu6Txx63vYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}